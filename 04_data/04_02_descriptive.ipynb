{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7koq6JnQOCh"
      },
      "source": [
        "## Class Announcements\n",
        "\n",
        "**Due Friday**:\n",
        "- D3\n",
        "- Project Proposal (Template in repo, turn in via repo)\n",
        "- Weekly project survey check in (optional, released Wednesdays!) on Canvas\n",
        "\n",
        "**Notes**:\n",
        "- Repo invites: missed yours? Ask on Piazza in private message to instructors!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MNnHnLCQOCm"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/COGS108/Lectures-Sp22/blob/master/04_data/04_02_descriptive.ipynb)\n",
        "\n",
        "# Descriptive Analysis\n",
        "\n",
        "- Size\n",
        "- Missingness\n",
        "- Shape\n",
        "- Central Tendency\n",
        "- Variability\n",
        "\n",
        "<div class=\"alert alert-success\">\n",
        "The goal of a <b>descriptive analysis</b> is to understand and summarize information about the variables stored in your dataset.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QhidWqVQOCn"
      },
      "source": [
        "### Setup\n",
        "\n",
        "The packages and settings we'll use in this workbook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDTnr11ZQOCn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (17, 7) #increase figure size\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set(style='white', font_scale=2) #set style\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from scipy.stats import uniform, norm, bernoulli, poisson\n",
        "\n",
        "#improve resolution\n",
        "#comment this line if erroring on your machine/screen\n",
        "%config InlineBackend.figure_format ='retina'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwWWb0jvQOCq"
      },
      "source": [
        "## The Data\n",
        "\n",
        "To walk through these concepts today, we're going to use your responses from after the Data Intuition Lecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfBJ6SvYQOCq"
      },
      "outputs": [],
      "source": [
        "# read data into Python\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/COGS108/Lectures-Sp22/master/04_data/data/fermi_wi22.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "JI9WyMvYQOCr"
      },
      "outputs": [],
      "source": [
        "# take a look at the data\n",
        "df[:35]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqrA84xbQOCr"
      },
      "source": [
        "### Data Cleaning & Wrangling\n",
        "\n",
        "Tidy Data Rules (Review):\n",
        "1. Every observation in a row\n",
        "2. Every variable in a column\n",
        "3. If multiple tables, column on which to merge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M4TW2p6QOCr"
      },
      "source": [
        "https://forms.gle/iW1HwXXqrRnvdkAw7\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/COGS108/Lectures-Sp22/master/04_data/images/qr-code(15).png\" width=600>\n",
        "\n",
        "#### Clicker Question #1\n",
        "\n",
        "Are these data in the tidy data format?\n",
        "\n",
        "- A) Yes, these data are ready to analyze\n",
        "- B) Yes, but there is more work to do before analysis\n",
        "- C) No, not tidy\n",
        "- D) Have no idea what you're talking about"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQuQpaFzQOCs"
      },
      "source": [
        "**Brainstorming**\n",
        "\n",
        "What should we do before we use these data?\n",
        "\n",
        "\n",
        "\n",
        "hmm...\n",
        "\n",
        "lets make a list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS_9fts-QOCs"
      },
      "source": [
        "- ideas from you\n",
        "- more ideas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1n1k7t_QOCt"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yK2IM8SsQOCt"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1_me38wQOCt"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R19o6rNPQOCt"
      },
      "source": [
        "- shorten column/variable names\n",
        "- standardize responses\n",
        "    - make measurements uniform\n",
        "    - remove units\n",
        "- string to int/float (want to work with #s)\n",
        "- consider missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "C5lKnYiaQOCu"
      },
      "outputs": [],
      "source": [
        "# change column names\n",
        "df.columns = ['timestamp', 'hair_growth', 'crammed', 'SAN_NYC']\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "JBzQQhYwQOCu"
      },
      "outputs": [],
      "source": [
        "# check type of each Series (column)\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sI8_KX_hQOCv"
      },
      "outputs": [],
      "source": [
        "df['timestamp'] = pd.to_datetime( df['timestamp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTKgIbnBQOCv"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--1Vd9i3QOCw"
      },
      "source": [
        "## Size\n",
        "\n",
        "As discussed previously, knowing and checking the size of your data helps you:\n",
        "- understand what information you have\n",
        "- know if it read into Python correctly\n",
        "- determine what analyses are appropriate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e4moRNqQOCw"
      },
      "outputs": [],
      "source": [
        "# determine rows and columns in df\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6JlSpM5QOCx"
      },
      "source": [
        "We now know that we have information about 85 students across 4 variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX3a4OCFQOCy"
      },
      "source": [
        "## Missingness\n",
        "\n",
        "Data can be missing for all kinds of reasons. It's your job to determine if:\n",
        "- values are missing at random\n",
        "- values are missing due to data entry errors\n",
        "- values are missing due to faulty data collection\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ga_9NtqDQOCy"
      },
      "outputs": [],
      "source": [
        "df.isnull().all(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO_d8RrpQOCz"
      },
      "outputs": [],
      "source": [
        "# True if row contains at least one null value\n",
        "# axis argument: 0 for reducing by ‘index’, 1 for reducing by ‘columns’,\n",
        "null_rows = df.isnull().any(axis='columns')\n",
        "df[null_rows].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZBt0F9UQOCz"
      },
      "outputs": [],
      "source": [
        "# columns with missing values\n",
        "df.columns[df.isnull().any(axis='rows')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "Ghca-B5UQOC0"
      },
      "outputs": [],
      "source": [
        "# number of missing values by column\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v5D6vEiQOC0"
      },
      "source": [
        "## Cleaning: Hair Growth\n",
        "\n",
        "How fast does human hair grow (cm/yr)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "zI4N3TvNQOC1"
      },
      "outputs": [],
      "source": [
        "# take a look at unique values\n",
        "df[\"hair_growth\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5Lf9FUVQOC1"
      },
      "outputs": [],
      "source": [
        "# standardize height column\n",
        "def standardize_hair(string):\n",
        "    \n",
        "    # Basic string pre-processing\n",
        "    string = string.lower()\n",
        "    string = string.strip()    \n",
        "\n",
        "    # take care of inclded unit cases   \n",
        "    string = string.replace(\"cm a year\", \"\")\n",
        "    string = string.replace(\"cm/year\", \"\")\n",
        "    string = string.replace(\"cm/ye\", \"\")\n",
        "    string = string.replace(\"centimeters\", \"\")\n",
        "    string = string.replace(\"cm per year\", \"\")\n",
        "    string = string.replace(\"cm/yr\", \"\")\n",
        "    string = string.replace(\"cm/1yr\", \"\")\n",
        "    string = string.replace(\"cm/y\", \"\")\n",
        "    string = string.replace(\"cm/1 year\", \"\")\n",
        "    string = string.replace(\"year\", \"\")\n",
        "    string = string.replace(\"yr\", \"\")\n",
        "    string = string.replace(\"cm\", \"\")    \n",
        "    string = string.replace(\"/\", \"\")\n",
        "    string = string.replace(\",\", \"\")\n",
        "    string = string.replace(\"eh, I'm  bald\", \"\")\n",
        "    string = string.replace('cm approx.', \"\")\n",
        "    string = string.replace(\"cm/yr, cuz it grows 2cm in a month\", \"\")\n",
        "    string = string.replace(\"^2\", \"0\")\n",
        "    \n",
        "    string = string.strip()\n",
        "\n",
        "    # convert to numeric\n",
        "    try:\n",
        "        output = float(eval(string))\n",
        "    except:\n",
        "        output = np.nan\n",
        "    \n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "FwhlyAUYQOC2"
      },
      "outputs": [],
      "source": [
        "# apply function across values in hair growth columns\n",
        "df[\"hair_growth\"] = df[\"hair_growth\"].apply(standardize_hair)\n",
        "df[\"hair_growth\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHREH6oAQOC3"
      },
      "source": [
        "## Cleaning: Crammed\n",
        "\n",
        "If every living person stood crammed together side-by-side, how large of an area would they occupy (km²)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "y_Lf36yBQOC4"
      },
      "outputs": [],
      "source": [
        "df['crammed'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6Q8h1gHQOC5"
      },
      "outputs": [],
      "source": [
        "# standardize crammed column\n",
        "def standardize_crammed(string):    \n",
        "    # Basic string pre-processing\n",
        "    string = string.lower()\n",
        "    string = string.strip()\n",
        "    \n",
        "    # take care of commas\n",
        "    string = string.replace(\",\", \"\")\n",
        "\n",
        "    # take care of specific cases\n",
        "    string = string.replace(\"texas?\", \"696200\")\n",
        "    string = string.replace(\"i'm bad at area lol\", \"NaN\")\n",
        "    string = string.replace(\"1.5 billion ft^2 to whatever that is in km^2\", \"139.35456\")\n",
        "    string = string.replace(\"the whole earth\",\"509600000\")\n",
        "    \n",
        "    # take care of inclded unit cases\n",
        "    string = string.replace(\"^2\", \"\")\n",
        "    string = string.replace(\"²\", \"\")\n",
        "    string = string.replace(\"km\", \"\")\n",
        "    \n",
        "    # take care of scientific notation / word cases\n",
        "    string = string.replace(\" million\", \"000000\")\n",
        "    string = string.replace(\" billion\", \"000000000\")\n",
        "\n",
        "    string = string.strip()\n",
        "\n",
        "\n",
        "    # convert to numeric\n",
        "    try:\n",
        "        output = float(eval(string))\n",
        "    except:\n",
        "        output = np.nan\n",
        "    \n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "kvVgrupyQOC6"
      },
      "outputs": [],
      "source": [
        "# apply function across values in crammed columns\n",
        "df[\"crammed\"] = df[\"crammed\"].apply(standardize_crammed)\n",
        "df[\"crammed\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy_d9u7MQOC7"
      },
      "source": [
        "## Cleaning: San Diego to NYC\n",
        "\n",
        "How many days would it take to walk from here to New York City (assuming no stopping to fix shoes, apply sunscreen, or for sleeping, eating, or other biological needs)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "j5IsLolYQOC8"
      },
      "outputs": [],
      "source": [
        "df['SAN_NYC'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0tpnHByQOC9"
      },
      "outputs": [],
      "source": [
        "# standardize distance column\n",
        "def standardize_distance(string):\n",
        "    \n",
        "    orig = string\n",
        "    output = None\n",
        "    \n",
        "    \n",
        "    # Basic string pre-processing\n",
        "    string = string.lower()\n",
        "    string = string.strip()\n",
        "    \n",
        "    # take care of commas\n",
        "    string = string.replace(\",\", \"\")\n",
        "    \n",
        "    # remove units\n",
        "    string = string.replace(\"days\", \"\")\n",
        "    \n",
        "    # remove uncertainty\n",
        "    string = string.replace(\"?\", \"\")\n",
        "\n",
        "    # remove modifier\n",
        "    string = string.replace(\"over\", \"\")\n",
        "\n",
        "    # take care of non-days answers\n",
        "    string = string.replace(\"2 months\", \"60\")\n",
        "    string = string.replace(\"4 weeks\", \"30\")\n",
        "\n",
        "    # take care of scientific notation \n",
        "    string = string.replace(\"10^3\", \"10000\")\n",
        "    \n",
        "    string = string.strip()\n",
        "\n",
        "    # convert to numeric\n",
        "    output = float(string)\n",
        "    \n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1mEFoN1QOC-"
      },
      "outputs": [],
      "source": [
        "# alternate approach to the same task\n",
        "def dist_helper(distance):\n",
        "    if len(distance) == 1:\n",
        "        return distance[0]\n",
        "    if distance[1] == '*':\n",
        "        return str(float(distance[0]) * float(distance[2]))\n",
        "    if distance[1] == '/':\n",
        "        return str(float(distance[0]) / float(distance[2]))\n",
        "\n",
        "df[\"SAN_NYC_alt\"] = pd.to_numeric(df[\"SAN_NYC\"].\n",
        "                              str.lower().\n",
        "                              replace(\",\", \"\").\n",
        "                              replace({\"days?\":\"\", \n",
        "                                       \"\\^\":\"e\", \"^\\([\\w */)=?]+$\":\"1000\", \n",
        "                                       \" months?\":\" * 30\", \n",
        "                                       \" hours?\": \" / 24\", \n",
        "                                       \" years?\": \" * 365\"}, regex = True).\n",
        "                              str.strip().\n",
        "                              str.split(' ').\n",
        "                              apply(dist_helper), errors = 'coerce')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wfRYDAzQOC_"
      },
      "source": [
        "# OOOPS!\n",
        "I left this as it was to correct a previous quarter's outputs.  We don't have the correct wrangling here for the current quarter.\n",
        "\n",
        "So let's leave this one as an exercise for YOU!  How do you want to handle wrangling this, dealing with all the possible issues, and making certain that each issue is handled!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lamOT4XQODA"
      },
      "outputs": [],
      "source": [
        "# insert your code here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3aw2gbjQODB"
      },
      "source": [
        "## Shape\n",
        "\n",
        "The shape of your data dictates what analyses you can do. Today, we'll review a number of different distributions (shapes) data can take and examples of data that take that distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fme710mzQODB"
      },
      "source": [
        "### Uniform Distribution\n",
        "\n",
        "<div class=\"alert alert-success\">\n",
        "The Uniform distribution has the property that every outcome has the equal probability of occurring. In other words, all outcomes are equally likely.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "PruHCd9JQODC"
      },
      "outputs": [],
      "source": [
        "dat = uniform.rvs(size=10000)\n",
        "sns.histplot(dat, bins=20);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN6lDnlxQODD"
      },
      "source": [
        "The **probability of rolling a given number on a fair die** is the same each time you roll the die - an example of a Uniform distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksNLqVf0QODD"
      },
      "source": [
        "The **probability of pulling a spade out of a deck of cards** is the same each time you pull a card out of the deck."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVx3X75OQODE"
      },
      "source": [
        "The **probability of flipping a heads each time you flip a fair coin** is the same each time you flip the coin."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwMrNbRmQODE"
      },
      "source": [
        "### Normal Distribution\n",
        "\n",
        "<div class=\"alert alert-success\">\n",
        "The Normal (also Gaussian, or 'Bell Curve') distribution, is a distribution defined by its mean and standard deviation.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "BOcGP9kjQODF"
      },
      "outputs": [],
      "source": [
        "# loc specifies mean\n",
        "# scale specifies the standard deviation\n",
        "dat = norm.rvs(loc=0, scale=1, size=10000)\n",
        "sns.histplot(dat, bins=20);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6wTI_KmQODF"
      },
      "source": [
        "With a standard Normal curve:\n",
        "- 68% of the values fall within one standard deviation [-1,1]\n",
        "- 95% of the values fall within two standard deviations [-2,2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA2mR8-NQODG"
      },
      "source": [
        "The **Normal distribution** is taught all over the place, and this is because it shows up all over the place. It's found in nature and across measurements we take all the time. It's also easy to understand and to work with statistically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN0k7Vb0QODG"
      },
      "source": [
        "The **average height of players in the NBA** follows a Normal distribution, with the average height being 6'7\". "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F2hNC5LQODH"
      },
      "source": [
        "If you were to **flip a fair coin 16 times** and count the number of heads each time...and then repeat this 1000 times, recording the number of heads each time, this would follow a Normal distribution. 8 would be the most popular number of heads, but there would be a normal distribution centered on 8 for these data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLR9SV1nQODH"
      },
      "source": [
        "### Bimodal Distributions\n",
        "\n",
        "<div class=\"alert alert-success\">\n",
        "A Bimodal Distribution is a distribution with two peaks - it often indicates that you have information about two groups. \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2ajZZJwQODH"
      },
      "outputs": [],
      "source": [
        "loc1, scale1, size1 = (90, 5, 175)\n",
        "loc2, scale2, size2 = (70, 5, 175)\n",
        "bi = np.concatenate([np.random.normal(loc=loc1, scale=scale1, size=size1), \n",
        "                     np.random.normal(loc=loc2, scale=scale2, size=size2)])\n",
        "sns.histplot(bi, bins=20);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfxcwVXYQODI"
      },
      "source": [
        "When **test scores in a class** are bimodal, often one peak describes those students who studied, while the other are those who didn't study or are struggling more with the course material."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azc5x_gEQODI"
      },
      "source": [
        "Another example of a bimodal distribution are **the number of visitors at a restaurant over time**. Often restaurants will get a peak of visitors at lunchtime and dinnertime, with lulls in between."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V1nCJfBQODI"
      },
      "source": [
        "### Bernoulli Distribution\n",
        "\n",
        "<div class=\"alert alert-success\">\n",
        "A Bernouilli Distribution is a binary distribution - it takes only two values (0 or 1), with some probability $p$. \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "tn4NANL6QODI"
      },
      "outputs": [],
      "source": [
        "r = bernoulli.rvs(0.1 , size=10000)\n",
        "sns.countplot(r, color='#7995C3');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrJqMNHfQODI"
      },
      "source": [
        "Usually the value 1 indicates 'success' and 0 indicates 'failure'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duHx5rhxQODJ"
      },
      "source": [
        "Whether a **team will win a championship or not** follows a Bernoulli distribution - the team will either win (1 = success) or lose (0 = failure), and there is some probability ($p$) assigned to each of those values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgzD52uiQODJ"
      },
      "source": [
        "Similarly, **whether you pass each exam at UCSD** follows a Bernoulli distribution - either you pass (1 = success) or you fail (0 = failure), and there is some probability assinged to each."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKtCCZDVQODJ"
      },
      "source": [
        "There are distributions that are built off of the Bernoulli Distribution, defined as follows:\n",
        "- **Binomial Distribution**: Number of success in $n$ trials\n",
        "- **Geometric Distribution**: Number of failures before the first success\n",
        "- **Negative Binomial Distribution**: Number of failures before the $x^{th}$ success"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L4B1GvmQODJ"
      },
      "source": [
        "### Poisson Distribution\n",
        "\n",
        "<div class=\"alert alert-success\">\n",
        "The Poisson Distribution models events in fixed intervals of time, given a known average rate (and independent occurences).\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "GmT9ObNNQODJ"
      },
      "outputs": [],
      "source": [
        "dat = poisson.rvs(mu=1, size=100000)\n",
        "sns.histplot(dat);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmIfx77qQODK"
      },
      "source": [
        "The **number of visitors a fast food drive-through gets each minute** follows a Poisson distribution. In this case, maybe the average is 3, but there's some variability around that number. \n",
        "\n",
        "A Poisson distribution can help calculate the probability of various events related to customers going through the drive-through at a restaurant. It will predict lulls (0 customers) and flurry of activity (5+ customers), allowing staff to plan and schedule more precisely."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X6kaRkGQODK"
      },
      "source": [
        "https://forms.gle/S6TZ6sE2XVmGuymZ9\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/COGS108/Lectures-Sp22/master/04_data/images/qr-code(16).png\" width=800>\n",
        "\n",
        "#### Clicker Question #2\n",
        "\n",
        "Which of the following would you expect to be **bimodal**?\n",
        "\n",
        "- A) heights from a random sample of females in the US\n",
        "- B) daily chance of winning the lottery\n",
        "- C) number of siblings everyone in this class has\n",
        "- D) distribution of speed limits in the US\n",
        "- E) ages of everyone in this class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_phOrgFyQODK"
      },
      "source": [
        "#### Clicker Question #3\n",
        "\n",
        "The \"winning\" number in a lottery follows a...\n",
        "\n",
        "- A) Normal Distribution\n",
        "- B) Uniform Distribution\n",
        "- C) Skewed-right distribution\n",
        "- D) Bimodal Distribtuion\n",
        "- E) Bernoulli Distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-vd7dsfQODK"
      },
      "source": [
        "#### Shape: Fermi Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "CcCs_rr8QODK"
      },
      "outputs": [],
      "source": [
        "sns.histplot(df['hair_growth'], kde=False, bins=20);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAKiyv19QODL"
      },
      "outputs": [],
      "source": [
        "sns.histplot(df['crammed'], kde=False, bins=200);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5Ql3QKdQODL"
      },
      "outputs": [],
      "source": [
        "df.crammed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "79w56l-aQODL"
      },
      "outputs": [],
      "source": [
        "sns.histplot(df.query(\"SAN_NYC < 1000\")['SAN_NYC'], kde=False, bins=20);\n",
        "\n",
        "#.query(\"SAN_NYC < 10000\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfjS2OmUQODL"
      },
      "source": [
        "### Data Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-9_LI0UQODM"
      },
      "source": [
        "We haven't discussed skewed distributions yet; however, all three variables here are **skewed right**, meaning there is a tail off to the right and most values are found near the lower portion of the distribution.\n",
        "\n",
        "These sorts of distributions are hard to analyze because deviations from the norm are driving the variation in the distribution...even though they are few in number.\n",
        "\n",
        "Often, when you have skwewed data, you'll want to transform the variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "vlR6Cq_lQODM"
      },
      "outputs": [],
      "source": [
        "# log transformed data\n",
        "sns.histplot(np.log10(df['hair_growth'][df['hair_growth'].notnull()]), bins=10)\n",
        "plt.xlabel('Hair Growth');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55VN8ODiQODM"
      },
      "source": [
        "After transforming the data, the values appear approximately Normal. Those high values are no longer driving variation in the data. However, we're now on a log-scale, which sometimes makes interpretation a bit more difficult."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfGH4D6TQODM"
      },
      "source": [
        "### Outliers\n",
        "\n",
        "Outliers are values that fall outside the typical range of your dataset. These can occur for all types of reasons:\n",
        "\n",
        "- data entry errors\n",
        "- poor sampling procedures\n",
        "- technical or mechanical errors\n",
        "- unexpected changes in weather\n",
        "- extreme values\n",
        "- people giving incorrect information\n",
        "- etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhDjt7mEQODM"
      },
      "source": [
        "<div class=\"alert alert-danger\">\n",
        "Caution: Observations should only be removed from your dataset if you have a valid reason to do so. If you remove outliers from your dataset, your report should be <b>very</b> clear that you did so.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL8HUb-PQODN"
      },
      "source": [
        "![outliers](https://raw.githubusercontent.com/COGS108/Lectures-Sp22/master/04_data/images/outliers.png)\n",
        "\n",
        "Link to Tweet: https://twitter.com/ChelseaParlett/status/1356285012375556109  \n",
        "Thread on possible approaches: https://twitter.com/IsabellaGhement/status/1356645319799308288"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXYl6RujQODN"
      },
      "source": [
        "## Central Tendency\n",
        "\n",
        "- mean \n",
        "- median\n",
        "- mode\n",
        "\n",
        "The Central Tendency tells you the 'typical' value for an observation in your dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvKWRY96QODN"
      },
      "source": [
        "### Mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNjm9gIQQODN"
      },
      "source": [
        "\n",
        "$$ \\bar x = \\frac{\\sum\\limits_{i = 1}^N x_i}N  $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf59nxslQODN"
      },
      "source": [
        "- $x_i$ = ith element of the sample\n",
        "- $\\bar x$ = sample mean\n",
        "- $N$ = sample size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iPoJYu6QODN"
      },
      "outputs": [],
      "source": [
        "# to calculate mean\n",
        "sum(df['hair_growth'])/len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm-OUEdKQODN"
      },
      "outputs": [],
      "source": [
        "df['hair_growth'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rN92ln1CQODO"
      },
      "outputs": [],
      "source": [
        "# check mean for each column\n",
        "df.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDLgyGcLQODO"
      },
      "source": [
        "### Median"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YULKo39BQODO"
      },
      "outputs": [],
      "source": [
        "# check median for each column\n",
        "df.median()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOyW0PmGQODO"
      },
      "source": [
        "### Median vs. Mean\n",
        "\n",
        "When the median and mean are not similar to one another...what's the best approach?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "l0z_wVN6QODP"
      },
      "outputs": [],
      "source": [
        "# relook at the distribution for bodywt\n",
        "sns.histplot(df['hair_growth'], bins=10);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "sVQJ9kMfQODP"
      },
      "outputs": [],
      "source": [
        "# median and mean for same series\n",
        "print( 'median: ', df['hair_growth'].median())\n",
        "print( 'mean: ', df['hair_growth'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "1rrMVJYNQODP"
      },
      "outputs": [],
      "source": [
        "# take a look at it all together\n",
        "ax = sns.histplot(df['hair_growth'], bins=10);\n",
        "ax.axvline(df['hair_growth'].mean(), color='darkred', linestyle='--', label='mean');\n",
        "ax.axvline(df['hair_growth'].median(), color='#2e2e2e', linestyle='--', label='median')\n",
        "ax.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7bBjkKkQODP"
      },
      "source": [
        "#### Clicker Question #4\n",
        "\n",
        "Which of the following is the best way to measure the central tendency of `hair_growth` in these data?\n",
        "\n",
        "- A) mean\n",
        "- B) median\n",
        "- C) mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "ZuH4Mm7LQODP"
      },
      "outputs": [],
      "source": [
        "# increase the number of bins here\n",
        "ax = sns.histplot(df['hair_growth'], bins=100);\n",
        "ax.axvline(df['hair_growth'].mean(), color='darkred', linestyle='--', label='mean');\n",
        "ax.axvline(df['hair_growth'].median(), color='#2e2e2e', linestyle='--', label='median')\n",
        "ax.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Bm4cN-ZQODP"
      },
      "source": [
        "#### How did y'all do?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "aWB9huz3QODQ"
      },
      "outputs": [],
      "source": [
        "# compare to actual value: 15 cm/year (~6 in)\n",
        "df[\"hair_growth\"].median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaPaV1TrQODQ"
      },
      "outputs": [],
      "source": [
        "# compare to actual value: 1,000-10,000 km^2)\n",
        "df['crammed'].median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "SLaOQgRjQODQ"
      },
      "outputs": [],
      "source": [
        "# compare to actual value: 38 days)\n",
        "df['SAN_NYC'].median()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh5gW37MQODQ"
      },
      "source": [
        "Calculating the mean and median of your sample is helpful when dealing with **quantitative variables**.\n",
        "\n",
        "When working with **categorical variables**, knowing the mode is helpful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZW1RIN8QODR"
      },
      "source": [
        "### Mode\n",
        "\n",
        "When working with categorical data, the mode is the most common value in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-h8tfLxQODR"
      },
      "source": [
        "## Variability\n",
        "\n",
        "- Range\n",
        "- IQR\n",
        "- Variance & Standard Deviation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed8e9UiZQODR"
      },
      "source": [
        "### Range\n",
        "\n",
        "The highest value minus the lowest value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBqKUHeSQODR"
      },
      "outputs": [],
      "source": [
        "# determine the 25th and 75th percentiles\n",
        "min_val = df['hair_growth'].min()\n",
        "max_val = df['hair_growth'].max()\n",
        "range_vals =  max_val - min_val\n",
        "print(max_val, '-' , min_val,' = ',  range_vals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1YqKHr1QODR"
      },
      "source": [
        "### IQR (Interquartile Range)\n",
        "\n",
        "75th percentile - 25th percentile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "VrTX55cbQODS"
      },
      "outputs": [],
      "source": [
        "# determine the 25th and 75th percentiles\n",
        "lower, upper = np.percentile(df['hair_growth'], [25, 75])\n",
        "lower, upper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StUY8KdSQODS"
      },
      "outputs": [],
      "source": [
        "# calculate IQR\n",
        "iqr = upper - lower\n",
        "iqr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlJQ2V-LQODS"
      },
      "outputs": [],
      "source": [
        "df['hair_growth'].quantile([0.25,0.75])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R38s9qbEQODS"
      },
      "outputs": [],
      "source": [
        "# visualizing IQR\n",
        "sns.boxplot(x='hair_growth', data=df);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVxzfTktQODS"
      },
      "source": [
        "### Variance & Standard Deviation\n",
        "\n",
        "- variance\n",
        "    - measures how close the values in the distribution are to the middle of the distribution\n",
        "    - average squared difference of the scores from  the mean\n",
        "- standard deviation\n",
        "    - square root of the variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-mDPbIrQODS"
      },
      "source": [
        "#### Variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9dpu7TPQODT"
      },
      "source": [
        "$$ s^2 = \\frac {\\sum\\limits_{i = 1}^N {\\left( {x_i - \\bar x} \\right)^2 }} {(N-1)} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az8FoBdkQODT"
      },
      "source": [
        "- $s^2$ = sample variance\n",
        "- $x_i$ = ith element of the sample\n",
        "- $\\bar x$ = mean of the sample\n",
        "- $N$ = sample size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XATGESWJQODT"
      },
      "outputs": [],
      "source": [
        "# the math behind sample variance\n",
        "var = sum((df['hair_growth'] - df['hair_growth'].mean()) ** 2 )/(len(df) - 1) \n",
        "var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7w6QQE4QODT"
      },
      "outputs": [],
      "source": [
        "# calculate variance using pandas\n",
        "var = df['hair_growth'].var()\n",
        "var"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs2Ar_dnQODT"
      },
      "source": [
        "#### Standard Deviation\n",
        "square root of the variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99_r1g1sQODT"
      },
      "source": [
        "$$ s = \\sqrt {\\frac {\\sum\\limits_{i = 1}^N {\\left( {x_i - \\bar x} \\right)^2 }} {(N-1)}} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "LoQbDvxPQODT"
      },
      "outputs": [],
      "source": [
        "np.sqrt(var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "fGbwokbtQODU"
      },
      "outputs": [],
      "source": [
        "# calculate variance using pandas\n",
        "sd = df['hair_growth'].std()\n",
        "sd "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FkuGfPrQODU"
      },
      "source": [
        "## Descriptive Tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rZ7XhwzQODU"
      },
      "source": [
        "![descriptive table](https://raw.githubusercontent.com/COGS108/Lectures-Sp22/master/04_data/images/descriptive.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43cqtPT7QODU"
      },
      "source": [
        "### Why Central Tendency Doesn't Tell the Whole Story"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCjw43qHQODU"
      },
      "outputs": [],
      "source": [
        "# generate two different normal distributions\n",
        "dist_1 = np.random.normal(5, 2, 1000)\n",
        "dist_2 = np.random.normal(5, 10, 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "JtyfbNPLQODU"
      },
      "outputs": [],
      "source": [
        "# plot distributions side by side\n",
        "sns.kdeplot(dist_1, label=\"mean: 5, sd: 2\")\n",
        "sns.kdeplot(dist_2, label=\"mean: 5, sd: 10\")\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ-Fa6aEQODU"
      },
      "source": [
        "## Anscombe's Quartet: A Cautionary Tale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH89HJm0QODV"
      },
      "source": [
        "Code in this example taken from [here](https://matplotlib.org/gallery/specialty_plots/anscombe.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF7Y9jDSQODV"
      },
      "outputs": [],
      "source": [
        "x = np.array([10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5])\n",
        "y1 = np.array([8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68])\n",
        "y2 = np.array([9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74])\n",
        "y3 = np.array([7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73])\n",
        "x4 = np.array([8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8])\n",
        "y4 = np.array([6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "305quqtuQODV"
      },
      "outputs": [],
      "source": [
        "def fit(x):\n",
        "    return 3 + 0.5 * x\n",
        "\n",
        "xfit = np.array([np.min(x), np.max(x)])\n",
        "\n",
        "plt.subplot(221)\n",
        "plt.plot(x, y1, 'ks', xfit, fit(xfit), 'r-', lw=2)\n",
        "plt.axis([2, 20, 2, 14])\n",
        "plt.setp(plt.gca(), xticklabels=[], yticks=(4, 8, 12), xticks=(0, 10, 20))\n",
        "plt.text(3, 12, 'I', fontsize=20)\n",
        "\n",
        "plt.subplot(222)\n",
        "plt.plot(x, y2, 'ks', xfit, fit(xfit), 'r-', lw=2)\n",
        "plt.axis([2, 20, 2, 14])\n",
        "plt.setp(plt.gca(), xticks=(0, 10, 20), xticklabels=[],\n",
        "         yticks=(4, 8, 12), yticklabels=[], )\n",
        "plt.text(3, 12, 'II', fontsize=20)\n",
        "\n",
        "plt.subplot(223)\n",
        "plt.plot(x, y3, 'ks', xfit, fit(xfit), 'r-', lw=2)\n",
        "plt.axis([2, 20, 2, 14])\n",
        "plt.text(3, 12, 'III', fontsize=20)\n",
        "plt.setp(plt.gca(), yticks=(4, 8, 12), xticks=(0, 10, 20))\n",
        "\n",
        "plt.subplot(224)\n",
        "xfit = np.array([np.min(x4), np.max(x4)])\n",
        "plt.plot(x4, y4, 'ks', xfit, fit(xfit), 'r-', lw=2)\n",
        "plt.axis([2, 20, 2, 14])\n",
        "plt.setp(plt.gca(), yticklabels=[], yticks=(4, 8, 12), xticks=(0, 10, 20))\n",
        "plt.text(3, 12, 'IV', fontsize=20)\n",
        "\n",
        "# verify the stats\n",
        "pairs = (x, y1), (x, y2), (x, y3), (x4, y4)\n",
        "for x, y in pairs:\n",
        "    print('mean=%1.2f, std=%1.2f, r=%1.2f' % (np.mean(y), np.std(y),\n",
        "          np.corrcoef(x, y)[0][1]))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "811tyQDnQODV"
      },
      "source": [
        "### Draw the Graph (What EDA is all about!)"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "rise": {
      "scroll": true
    },
    "colab": {
      "name": "04_02_descriptive.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}